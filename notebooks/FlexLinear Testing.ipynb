{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: in order for this notebook to run, the \"updateOutput...\" functions must not be using pointers (precedded by &) in the c++ code... SWIG doesn't seem to like it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from linguamind import linalg as la, nlp, nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = la.Seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_input = la.Vector(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<linguamind.linalg.Vector; proxy of <Swig Object of type 'Vector *' at 0x109c8e3c0> >"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_input.uniform(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_input_np = np.zeros(8)\n",
    "for i in range(8):\n",
    "    sample_input_np[i] = sample_input[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<linguamind.linalg.Matrix; proxy of <Swig Object of type 'Matrix *' at 0x109c8e630> >"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = nn.FlexLinear(8,16)\n",
    "layer.weights.uniform(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_np = np.zeros((8,16))\n",
    "for i in range(8):\n",
    "    for j in range(16):\n",
    "        weights_np[i][j] = layer.weights[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_np = sample_input_np.dot(weights_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delta = la.Vector(16)\n",
    "delta.uniform(seed)\n",
    "delta_np = np.array(delta.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dense Dense Forward Prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer.getOutput().zero()\n",
    "for iter in range(100):\n",
    "    layer.updateOutputDenseToDense(sample_input)\n",
    "    out_lm = layer.getOutput().get()\n",
    "\n",
    "    for i in range(16):\n",
    "        assert(out_lm[i] - out_np[i] < 1e-5)\n",
    "        \n",
    "    layer.updateInputGrad(delta)\n",
    "    \n",
    "    for i in range(8):\n",
    "        assert(np.abs(delta_np.dot(weights_np.T)[i] - layer.getInputGrad().get()[i]) < 1e-5)\n",
    "        \n",
    "layer.swapInputOutputSparsity()\n",
    "\n",
    "layer.getOutput().zero()\n",
    "for iter in range(100):\n",
    "    layer.updateOutputDenseToDense(sample_input)\n",
    "    out_lm = layer.getOutput().get()\n",
    "\n",
    "    for i in range(16):\n",
    "        assert(out_lm[i] - out_np[i] < 1e-5)\n",
    "    \n",
    "    for i in range(8):\n",
    "        assert(np.abs(delta_np.dot(weights_np.T)[i] - layer.getInputGrad().get()[i]) < 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dense -> Weighted Sparse Forward Prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer.getOutput().zero()\n",
    "layer.getInputGrad().zero()\n",
    "\n",
    "for iter in range(100):\n",
    "    layer.updateOutputDenseToWeightedSparse(sample_input,list(range(16)))\n",
    "    out_lm = layer.getOutput().get()\n",
    "\n",
    "    for i in range(16):\n",
    "        assert(np.abs(out_lm[i] - out_np[i]) < 1e-5)\n",
    "#     assert(out_lm[15] == 0)\n",
    "    \n",
    "    layer.updateInputGrad(delta)\n",
    "    \n",
    "    for i in range(8):\n",
    "        assert(np.abs(delta_np.dot(weights_np.T)[i] - layer.getInputGrad().get()[i]) < 1e-5)\n",
    "        \n",
    "layer.swapInputOutputSparsity()\n",
    "    \n",
    "layer.getOutput().zero()\n",
    "for iter in range(100):\n",
    "    layer.updateOutputDenseToWeightedSparse(sample_input,list(range(16)))\n",
    "    out_lm = layer.getOutput().get()\n",
    "\n",
    "    for i in range(16):\n",
    "        assert(np.abs(out_lm[i] - out_np[i]) < 1e-5)\n",
    "#     assert(out_lm[15] == 0)\n",
    "    \n",
    "    layer.updateInputGrad(delta)\n",
    "    \n",
    "    for i in range(8):\n",
    "        assert(np.abs(delta_np.dot(weights_np.T)[i] - layer.getInputGrad().get()[i]) < 1e-5)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Weighted Sparse -> Dense Forward Prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer.getOutput().zero()\n",
    "for iter in range(100):\n",
    "    layer.updateOutputWeightedSparseToDense(sample_input,list(range(8)))\n",
    "    out_lm = layer.getOutput().get()\n",
    "\n",
    "    for i in range(8):\n",
    "        assert(np.abs(out_lm[i] - out_np[i]) < 1e-5)\n",
    "        \n",
    "    layer.updateInputGrad(delta)\n",
    "    \n",
    "    for i in range(8):\n",
    "        assert(np.abs(delta_np.dot(weights_np.T)[i] - layer.getInputGrad().get()[i]) < 1e-5)\n",
    "\n",
    "        \n",
    "layer.swapInputOutputSparsity()\n",
    "    \n",
    "layer.getOutput().zero()\n",
    "for iter in range(100):\n",
    "    layer.updateOutputWeightedSparseToDense(sample_input,list(range(8)))\n",
    "    out_lm = layer.getOutput().get()\n",
    "\n",
    "    for i in range(8):\n",
    "        assert(np.abs(out_lm[i] - out_np[i]) < 1e-5)\n",
    "\n",
    "    layer.updateInputGrad(delta)\n",
    "    \n",
    "    for i in range(8):\n",
    "        assert(np.abs(delta_np.dot(weights_np.T)[i] - layer.getInputGrad().get()[i]) < 1e-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Weighted Sparse -> Weighted Sparse Forward Prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer.getOutput().zero()\n",
    "for iter in range(100):\n",
    "    layer.updateOutputWeightedSparseToWeightedSparse(sample_input,list(range(8)),list(range(16)))\n",
    "    out_lm = layer.getOutput().get()\n",
    "\n",
    "    for i in range(8):\n",
    "        assert(np.abs(out_lm[i] - out_np[i]) < 1e-5)\n",
    "\n",
    "        \n",
    "layer.swapInputOutputSparsity()\n",
    "    \n",
    "layer.getOutput().zero()\n",
    "for iter in range(100):\n",
    "    layer.updateOutputWeightedSparseToWeightedSparse(sample_input,list(range(8)),list(range(16)))\n",
    "    out_lm = layer.getOutput().get()\n",
    "\n",
    "    for i in range(8):\n",
    "        assert(np.abs(out_lm[i] - out_np[i]) < 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Binary Sparse -> Dense Forward Prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bin_out_np = np.ones(8).dot(weights_np) / 8\n",
    "layer.getOutput().zero()\n",
    "for iter in range(100):\n",
    "    layer.updateOutputBinarySparseToDense(list(range(8)))\n",
    "    out_lm = layer.getOutput().get()\n",
    "\n",
    "    for i in range(8):\n",
    "        assert(np.abs(bin_out_np[i] - out_lm[i]) < 1e-5)\n",
    "\n",
    "    layer.updateInputGrad(delta)\n",
    "    \n",
    "    for i in range(8):\n",
    "        assert(np.abs(delta_np.dot(weights_np.T)[i] - layer.getInputGrad().get()[i]) < 1e-5)\n",
    "\n",
    "layer.swapInputOutputSparsity()\n",
    "    \n",
    "layer.getOutput().zero()\n",
    "for iter in range(100):\n",
    "    layer.updateOutputBinarySparseToDense(list(range(8)))\n",
    "    out_lm = layer.getOutput().get()\n",
    "\n",
    "    for i in range(8):\n",
    "        assert(np.abs(bin_out_np[i] - out_lm[i]) < 1e-5)\n",
    "    \n",
    "    layer.updateInputGrad(delta)\n",
    "    \n",
    "    for i in range(8):\n",
    "        assert(np.abs(delta_np.dot(weights_np.T)[i] - layer.getInputGrad().get()[i]) < 1e-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Binary Sparse -> Weighted Sparse Forward Prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bin_out_np = np.ones(8).dot(weights_np) / 8\n",
    "layer.getOutput().zero()\n",
    "for iter in range(100):\n",
    "    layer.updateOutputBinarySparseToWeightedSparse(list(range(8)),list(range(16)))\n",
    "    out_lm = layer.getOutput().get()\n",
    "\n",
    "    for i in range(8):\n",
    "        assert(np.abs(bin_out_np[i] - out_lm[i]) < 1e-5)\n",
    "\n",
    "        \n",
    "layer.swapInputOutputSparsity()\n",
    "    \n",
    "layer.getOutput().zero()\n",
    "for iter in range(100):\n",
    "    layer.updateOutputBinarySparseToWeightedSparse(list(range(8)),list(range(16)))\n",
    "    out_lm = layer.getOutput().get()\n",
    "\n",
    "    for i in range(8):\n",
    "        assert(np.abs(bin_out_np[i] - out_lm[i]) < 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Matrix Transposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for iter in range(100):\n",
    "    mat = la.Matrix(8,16)\n",
    "    mat.uniform(seed)\n",
    "\n",
    "    matrix_np = np.zeros((8,16))\n",
    "\n",
    "    for i in range(8):\n",
    "        for j in range(16):\n",
    "            matrix_np[i][j] = mat[i][j]\n",
    "\n",
    "    mat.transpose()\n",
    "\n",
    "    for i in range(16):\n",
    "        for j in range(8):\n",
    "            assert(matrix_np.T[i][j] - mat[i][j] < 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
