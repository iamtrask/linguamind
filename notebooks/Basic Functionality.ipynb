{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import linguamind.nlp as nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import linguamind.linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = nlp.Text(\"hello world\",\"BIIIIOBIIII\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = text.getVocab(\"tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# text = lm.Text(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = lm.Text(\"hello world\",\"BIIIIOBIIII\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab = text.getVocab(\"tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "world\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(vocab.size):\n",
    "    print vocab.getTermAtIndex(i).letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.getSequence(\"tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#NLP Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two Types of Component:\n",
    "- word level\n",
    "- sentence level\n",
    "- document level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = lm.Text(\"/my/folder/of/files\") # atempts to autodetect file type\n",
    "c = lm.Text(path=\"myfile.txt\",type=\"raw\")\n",
    "c = lm.Text(path=\"myfile.txt\",type=\"csv-token\") # one token per line in CSV\n",
    "c = lm.Text(path=\"myfile.txt\",type=\"csv-segment\") # text segment per line in CSV\n",
    "c = lm.Text(path=\"myfile.txt\",type=\"prefix__label__\") # one sentence per line with special labels\n",
    "c = lm.Text(path=\"myfile.txt\",type=\"json\")\n",
    "\n",
    "# document level raw text\n",
    "d1 = lm.Text(\"This is my sentence.\")\n",
    "d2 = lm.Text(\"myfile.txt\")\n",
    "\n",
    "c = lm.Text([d1,d2]) #form documents into Corpus\n",
    "\n",
    "# document level text with labels\n",
    "contents = {}\n",
    "contents[\"text\"] = \"This is my sentence. This is another one.\"\n",
    "contents[\"date\"] = 1997\n",
    "d = lm.Text(contents)\n",
    "\n",
    "# sentence level text with labels\n",
    "contents = {}\n",
    "contents[\"text\"] = \"This is my sentence.\"\n",
    "contents[\"sentiment\"] = \"Positive\"\n",
    "contents[\"speaker\"] = \"John Locke\"\n",
    "d = lm.Text(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tok = lm.Segmenter(name=\"tokenizer\",lang=\"en\")\n",
    "eos = lm.Segmenter(name=\"eos\",lang=\"en\")\n",
    "\n",
    "# document level text with labels\n",
    "contents = {}\n",
    "contents[\"text\"] = \"This is my sentence. This is another one.\"\n",
    "contents[\"date\"] = 1997\n",
    "d = lm.Text(contents)\n",
    "\n",
    "tok.segment(d)\n",
    "eos.segment(d)\n",
    "\n",
    "print d[\"text\"] # \"This is my sentence. This is another one.\"\n",
    "print d[\"tokens\"] # [\"This\", \"is\"...\n",
    "print d[\"sentences\"] # [[\"This\", \"is\", \"my\", \"sentence\",\".\"],[\"This\",\"is\",\"another\",\"one\",\".\"]]                \n",
    "                     \n",
    "pos = lm.Classifier(name=\"pos\")\n",
    "pos.predict(d)\n",
    "\n",
    "print d[\"sentences\"] # [[{\"token\":\"This\",\"POS\":\"NNP\"},...                \n",
    "\n",
    "sentiment = lm.Classifier(name=\"sentiment\")\n",
    "sentiment.predict(d)\n",
    "print d[\"sentences\"] # [{\"sentiment\":\"Positive\",\"tokens\":[{\"token\":\"This\",\"POS\":\"NNP\"},..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Creating Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a Segmenter (tokenizer)\n",
    "contents = {}\n",
    "contents[\"text\"] = \"I like pie.\"\n",
    "contents[\"char_segs\"] = \"BOBIIIOBIIB\"\n",
    "d = lm.Text(contents)\n",
    "\n",
    "feats=[[\"text_-2\",\"text_-1\"],\"text_-1\",\"text_0\",\"text_1\",[\"text_1\",\"text_2\"]]\n",
    "\n",
    "ambiguity_hash = lm.AmbiguityHash(d,feats,\"char_segs\",threshold=0.95,min_count=5)\n",
    "\n",
    "percept_model = lm.ml.Sequential()\n",
    "percept_model.add(lm.ml.Linear(size=[d.getVocab(\"text\").size() * 10],encoding=\"hashtable\"))\n",
    "percept_model.add(lm.ml.LogSoftmax())\n",
    "\n",
    "percept_loss = lm.ml.PerceptronLoss()\n",
    "percept_optimizer = lm.ml.optim.PerceptronUpdate()\n",
    "percept_searcher = lm.ml.search.BeamSearch(beam=5)\n",
    "\n",
    "# where available in leau of calling all the forward/backprop logic from Python slowing things down\n",
    "tokenizer = lm.ml.trainer.FastSegmentationTrainer(d,\"char_segs\",feats,percept_model,percept_loss,percept_searcher,inherits=[ambiguity_hash],threads=50)\n",
    "\n",
    "tokenizer.segment(d,\"tokens\") #generates new vocab for what was segmented\n",
    "\n",
    "eos = lm.pretrained.Segmenter(name=\"eos\",lang=\"en\")\n",
    "eos.segment(d,\"sentences\",ignore_vocab=True) # does not generate a new vocab for what was segmented\n",
    "\n",
    "# https://github.com/oxford-cs-ml-2015/practical6/blob/master/train.lua\n",
    "lstm_hidden = 50\n",
    "seq_length = 16\n",
    "\n",
    "layers = list()\n",
    "for i in range(seq_length):\n",
    "    layer = {}\n",
    "    \n",
    "    inputs = {}\n",
    "    layer['embed'] = lm.ml.Embedding(d.getVocab(\"token\").size(),lstm_hidden)\n",
    "    layer['lstm'] = lm.ml.LSTM(lstm_hidden,input_x=layer['embed'],input_h=layers[i-1]['lstm']['h'])\n",
    "    layer['softmax'] = lm.ml.LogElasticHierarchicalSoftmax(input=layer['lstm']['h'],size=(lstm_hidden,d.getVocab(\"token\").size()),sample_rate=0.001)\n",
    "    layer['criterion'] = lm.ml.LogElasticHierarchicalSoftmaxLoss()\n",
    "    layers.append(layer)\n",
    "\n",
    "word_language_model_searcher = lm.ml.search.BeamSearch(beam=5)\n",
    "percept_optimizer = lm.ml.optim.SGD()\n",
    "word_language_model = lm.ml.trainer.FastLanguageModelTrainer(d,layers,word_language_model_searcher,percept_optimizer,predict_on=\"token\",bound_on=\"sentence\",threads=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ML Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ambiguity Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Perceptron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Neural Index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
