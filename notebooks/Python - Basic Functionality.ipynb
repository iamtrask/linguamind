{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import linguamind.linalg as la\n",
    "import linguamind.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        \n",
    "        self.sparse_output = False\n",
    "        self.sparse_input = False\n",
    "        \n",
    "        self.input_dim = input_dim # embedding dim\n",
    "        self.output_dim = output_dim # output vocab size \n",
    "        \n",
    "        self.weights = la.Matrix(output_dim,input_dim)\n",
    "        \n",
    "        self.output = la.Vector(output_dim).zero()\n",
    "        self.input_grad = la.Vector(self.input_dim).zero()\n",
    "        \n",
    "        self.full_output_indices = list(range(self.output_dim))\n",
    "    \n",
    "    def updateOutput(self, input, output_indices=None):\n",
    "        for index in range(self.output_dim):\n",
    "            self.output.doti(index,input, self.weights[index])\n",
    "    \n",
    "    def updateInputGrad(self, output_grad):\n",
    "        self.input_grad.set(self.weights[0],output_grad[0]) \n",
    "        for index in range(self.output_dim-1):\n",
    "            self.input_grad.addi(self.weights[index+1],output_grad[index+1])\n",
    "            \n",
    "    def accGradParameters(self, input, output_grad, alpha):\n",
    "        for index in range(self.output_dim):\n",
    "            self.weights[index].addi(input,output_grad[index] * -alpha)\n",
    "\n",
    "class Relu():\n",
    "    def __init__(self, dim):\n",
    "        self.resize(dim)\n",
    "        self.sparse_output = False\n",
    "        self.sparse_input = False\n",
    "    \n",
    "    \n",
    "    def resize(self,dim):\n",
    "        self.input_dim = dim\n",
    "        self.output_dim = dim\n",
    "        \n",
    "        self.weights = None\n",
    "        self.output_indices = list(range(dim))\n",
    "        \n",
    "        self.output = la.Vector(self.output_dim).zero()\n",
    "        self.input_grad = la.Vector(self.input_dim).zero()\n",
    "        \n",
    "        self.full_output_indices = list(range(self.output_dim))\n",
    "    \n",
    "    def updateOutput(self, input, output_indices = None):\n",
    "\n",
    "        if(output_indices is None):\n",
    "            output_indices = list(range(self.output_dim))\n",
    "        self.output_indices = output_indices\n",
    "        \n",
    "        self.input_grad *= 0\n",
    "        self.input_grad += input\n",
    "        self.input_grad >= 0\n",
    "        \n",
    "        self.output *= 0\n",
    "        self.output += input\n",
    "        self.output *= self.input_grad\n",
    "        \n",
    "    def updateInputGrad(self, output_grad):\n",
    "        self.input_grad *= output_grad\n",
    "        \n",
    "    def accGradParameters(self,input, output_grad, alpha):\n",
    "        \"do nothing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MSECriterion():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\n",
    "        self.grad = la.Vector(32).zero()\n",
    "        \n",
    "    def forward(self,input,target,output_indices):\n",
    "        self.output = input\n",
    "        self.tmp_error = la.Vector(len(output_indices)).zero()\n",
    "        for i,index in enumerate(output_indices):\n",
    "            self.tmp_error[i] = self.output[index] - target[i]\n",
    "            \n",
    "        self.error = 0\n",
    "        for i in range(len(output_indices)):\n",
    "            self.error += self.tmp_error[i] * self.tmp_error[i]\n",
    "        self.error /= len(self.tmp_error)\n",
    "        \n",
    "        return self.error\n",
    "    \n",
    "    def backward(self,output, target,output_indices):\n",
    "        if(self.grad.size != output.size):\n",
    "            self.grad = la.Vector(output.size).zero()\n",
    "        for i,index in enumerate(output_indices):\n",
    "            self.grad[index] = output[index] - target[i]\n",
    "#             print(str(output[index]) + \" - \" + str(target[i]))\n",
    "        return self.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Sequential():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\n",
    "        self.layers = list()\n",
    "    \n",
    "    def add(self,layer):\n",
    "        \n",
    "        self.layers.append(layer)\n",
    "        self.output = self.layers[-1].output\n",
    "    \n",
    "    def forward(self,input_indices=(1,3,2), output_indices=(1,2,4)):\n",
    "        \n",
    "        self.layers[0].updateOutput(None, input_indices)\n",
    "        \n",
    "        sparse_output_until_end = False\n",
    "        \n",
    "        \n",
    "        for index in range(len(self.layers)-2):\n",
    "            if(self.layers[index+1].sparse_output):\n",
    "                sparse_output_until_end = True\n",
    "                \n",
    "            if(sparse_output_until_end):\n",
    "                self.layers[index+1].updateOutput(self.layers[index].output,output_indices)\n",
    "            else:\n",
    "                self.layers[index+1].updateOutput(self.layers[index].output,self.layers[index+1].full_output_indices)\n",
    "            \n",
    "        self.layers[-1].updateOutput(self.layers[-2].output,output_indices)\n",
    "        \n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, grad, output_indices):\n",
    "        \n",
    "        self.layers[-1].updateInputGrad(grad)\n",
    "        sparse_output_until_end = True\n",
    "        for i in reversed(range(len(self.layers)-2)):\n",
    "            if(sparse_output_until_end):\n",
    "                self.layers[i+1].updateInputGrad(self.layers[i+2].input_grad)\n",
    "            else:\n",
    "                self.layers[i+1].updateInputGrad(self.layers[i+2].input_grad)\n",
    "            if(self.layers[i+1].sparse_output == True):\n",
    "                sparse_output_until_end = False\n",
    "                \n",
    "class StochasticGradient():\n",
    "    \n",
    "    def __init__(self,mlp,criterion,alpha = 0.01):\n",
    "        self.mlp = mlp\n",
    "        self.criterion = criterion\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def train(self,input_indices, output_indices, target_values): \n",
    "        \n",
    "        pred = self.mlp.forward(input_indices,output_indices)\n",
    "        error = self.criterion.forward(pred,target_values,output_indices)\n",
    "        self.mlp.backward(self.criterion.backward(pred,target_values,output_indices),output_indices)\n",
    "\n",
    "        # update all but last layer\n",
    "        prev_layer_output = None        \n",
    "        for i in range(len(self.mlp.layers)-1):\n",
    "            mlp.layers[i].accGradParameters(prev_layer_output,mlp.layers[i+1].input_grad,self.alpha)\n",
    "            prev_layer_output = mlp.layers[i].output\n",
    "                    \n",
    "        # update weights for output with criterion gradient        \n",
    "        mlp.layers[-1].accGradParameters(mlp.layers[-2].output,criterion.grad,self.alpha)\n",
    "            \n",
    "        return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SparseLinearInput():\n",
    "    \n",
    "    def __init__(self,input_dim, output_dim):\n",
    "        \n",
    "        self.sparse_output = False\n",
    "        self.sparse_input = True\n",
    "        \n",
    "        self.input_dim = input_dim # vocab size\n",
    "        self.output_dim = output_dim # embedding dim\n",
    "        \n",
    "        self.weights = la.Matrix(input_dim,output_dim)\n",
    "        \n",
    "        self.input_indices = list(range(self.input_dim))\n",
    "        self.full_output_indices = list(range(self.output_dim))        \n",
    "        \n",
    "        self.output = la.Vector(output_dim).zero()\n",
    "        \n",
    "        self.input_grad = None;\n",
    "        \n",
    "    def updateOutput(self, input, input_indices):\n",
    "        self.input_indices = input_indices\n",
    "        \n",
    "        self.output.zero()\n",
    "        for index in self.input_indices:\n",
    "            self.output += self.weights[index]\n",
    "    \n",
    "    def updateInputGrad(self, output_grad):\n",
    "        \"do nothing\"\n",
    "    \n",
    "    def accGradParameters(self, input, output_grad, alpha):\n",
    "        # input is all 1s and is not used\n",
    "        for index in self.input_indices:\n",
    "            self.weights[index].addi(output_grad,-alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SparseLinearOutput():\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        \n",
    "        self.sparse_output = True\n",
    "        self.sparse_input = False\n",
    "        \n",
    "        self.input_dim = input_dim # embedding dim\n",
    "        self.output_dim = output_dim # output vocab size \n",
    "        \n",
    "        self.weights = la.Matrix(output_dim,input_dim)\n",
    "        \n",
    "        self.output = la.Vector(output_dim).zero()\n",
    "        self.output_indices = list(range(self.output_dim))\n",
    "        self.full_output_indices = list(range(self.output_dim))        \n",
    "        \n",
    "        self.input_grad = la.Vector(self.input_dim).zero()\n",
    "    \n",
    "    def updateOutput(self, input, output_indices=None):\n",
    "        if(output_indices is None):\n",
    "            output_indices = list(range(self.output_dim))\n",
    "        self.output_indices = output_indices\n",
    "        \n",
    "        for index in self.output_indices:\n",
    "            self.output.doti(index,input, self.weights[index])\n",
    "            \n",
    "    def updateInputGrad(self,output_grad):\n",
    "        self.input_grad.set(self.weights[self.output_indices[0]],output_grad[self.output_indices[0]]) \n",
    "        for index in self.output_indices[1:]:\n",
    "            self.input_grad.addi(self.weights[index],output_grad[index]) \n",
    "    \n",
    "    def accGradParameters(self, input, output_grad, alpha):\n",
    "        for index in self.output_indices:\n",
    "            self.weights[index].addi(input,output_grad[index] * -alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<linguamind.linalg.Matrix; proxy of <Swig Object of type 'Matrix *' at 0x104a74a80> >"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = la.Seed(1)\n",
    "\n",
    "syn0 = SparseLinearInput(100,64)\n",
    "syn0.weights.uniform(seed)\n",
    "syn0.weights -= 0.5\n",
    "syn0.weights /= 50\n",
    "\n",
    "syn1 = Linear(64,32)\n",
    "syn1.weights.uniform(seed)\n",
    "syn1.weights -= 0.5\n",
    "syn1.weights /= 50\n",
    "\n",
    "syn2 = Linear(32,16)\n",
    "syn2.weights.uniform(seed)\n",
    "syn2.weights -= 0.5\n",
    "syn2.weights /= 50\n",
    "\n",
    "syn3 = SparseLinearOutput(16,100)\n",
    "syn3.weights.uniform(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp = Sequential()\n",
    "\n",
    "mlp.add(syn0)\n",
    "mlp.add(syn1)\n",
    "# mlp.add(Relu(32))\n",
    "mlp.add(syn2)\n",
    "mlp.add(Relu(16))\n",
    "mlp.add(syn3)\n",
    "mlp.add(Relu(100))\n",
    "\n",
    "criterion = MSECriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_indices = (1,2,3,4)\n",
    "output_indices = (1,2,3,4,5,6,20,4)\n",
    "\n",
    "target = la.Vector(len(output_indices))\n",
    "target.zero()\n",
    "target.set(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = mlp.forward(input_indices, output_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optim = StochasticGradient(mlp,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12498991388776334\n",
      "0.12498972023408507\n",
      "0.12498952658142347\n",
      "0.12498933292978155\n",
      "0.12498912437865183\n",
      "0.12498893072907694\n",
      "0.12498873708053435\n",
      "0.12498854343302912\n",
      "0.12498834978656745\n",
      "0.12498815614115173\n",
      "0.1249879475963455\n",
      "0.12498775395305069\n",
      "0.12498756031081573\n",
      "0.12498736666964828\n",
      "0.12498715812915558\n",
      "0.12498696449014744\n",
      "0.12498677085222118\n",
      "0.12498656231502024\n",
      "0.12498636867928554\n",
      "0.12498617504464829\n",
      "0.12498596651078928\n",
      "0.12498577287837814\n",
      "0.12498556434677889\n",
      "0.1249853707166141\n",
      "0.12498516218730055\n",
      "0.12498496855940691\n",
      "0.12498476003240178\n",
      "0.12498456640680526\n",
      "0.12498435788213318\n",
      "0.12498416425885958\n",
      "0.12498395573654537\n",
      "0.12498374721542695\n",
      "0.12498355359569487\n",
      "0.12498334507697728\n",
      "0.12498313655947689\n",
      "0.12498294294334439\n",
      "0.12498273442828617\n",
      "0.12498252591446515\n",
      "0.12498231740189229\n",
      "0.12498210889057064\n",
      "0.12498190038051338\n",
      "0.1249817067717939\n",
      "0.12498149826426785\n",
      "0.12498128975802575\n",
      "0.12498108125307868\n",
      "0.1249808727494312\n",
      "0.12498066424709356\n",
      "0.12498045574607487\n",
      "0.12498023234640095\n",
      "0.12498002384805607\n",
      "0.12497981535105517\n",
      "0.12497960685541007\n",
      "0.12497939836112339\n",
      "0.1249791749682903\n",
      "0.12497896647677242\n",
      "0.12497875798664221\n",
      "0.12497853459803372\n",
      "0.12497832611072672\n",
      "0.12497811762483738\n",
      "0.12497789424053837\n",
      "0.12497768575753125\n",
      "0.12497746237615996\n",
      "0.12497723899626989\n",
      "0.12497703051767216\n",
      "0.12497680714077634\n",
      "0.12497658376539736\n",
      "0.12497637529130348\n",
      "0.12497615191898069\n",
      "0.12497592854821044\n",
      "0.12497570517900215\n",
      "0.12497548181136914\n",
      "0.12497525844532366\n",
      "0.12497503508087388\n",
      "0.12497481171803468\n",
      "0.12497458835682038\n",
      "0.12497436499724002\n",
      "0.12497414163930577\n",
      "0.1249739182830322\n",
      "0.12497369492842997\n",
      "0.12497347157551518\n",
      "0.1249732333247322\n",
      "0.12497300997523939\n",
      "0.12497278662747494\n",
      "0.12497254838192687\n",
      "0.124972325037666\n",
      "0.12497208679567443\n",
      "0.12497186345497915\n",
      "0.12497162521660697\n",
      "0.12497138698007279\n",
      "0.12497116364483006\n",
      "0.12497092541200351\n",
      "0.12497068718105717\n",
      "0.12497044895200661\n",
      "0.12497021072487352\n",
      "0.12496997249966865\n",
      "0.12496973427640329\n",
      "0.12496949605510205\n",
      "0.1249692578357791\n",
      "0.1249690196184488\n",
      "0.12496878140313045\n"
     ]
    }
   ],
   "source": [
    "for iter in range(100):\n",
    "    print(optim.train(input_indices,output_indices,target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12498991388776334\n",
      "0.12498972023408507\n",
      "0.12498952658142347\n",
      "0.12498933292978155\n",
      "0.12498912437865183\n",
      "0.12498893072907694\n",
      "0.12498873708053435\n",
      "0.12498854343302912\n",
      "0.12498834978656749\n",
      "0.12498815614115173\n",
      "0.1249879475963455\n",
      "0.12498775395305069\n",
      "0.12498756031081573\n",
      "0.12498736666964828\n",
      "0.12498715812915558\n",
      "0.12498696449014744\n",
      "0.12498677085222118\n",
      "0.12498656231502024\n",
      "0.12498636867928554\n",
      "0.12498617504464829\n",
      "0.12498596651078928\n",
      "0.12498577287837814\n",
      "0.12498556434677889\n",
      "0.1249853707166141\n",
      "0.12498516218730055\n",
      "0.12498496855940691\n",
      "0.12498476003240178\n",
      "0.12498456640680526\n",
      "0.12498435788213322\n",
      "0.12498416425885958\n",
      "0.12498395573654537\n",
      "0.12498374721542695\n",
      "0.12498355359569487\n",
      "0.12498334507697752\n",
      "0.12498313655947689\n",
      "0.12498294294334439\n",
      "0.12498273442828617\n",
      "0.12498252591446515\n",
      "0.12498231740189229\n",
      "0.12498210889057064\n",
      "0.12498190038051338\n",
      "0.1249817067717939\n",
      "0.12498149826426785\n",
      "0.12498128975802575\n",
      "0.12498108125307868\n",
      "0.1249808727494312\n",
      "0.12498066424709356\n",
      "0.12498045574607487\n",
      "0.1249802323464014\n",
      "0.12498002384805607\n",
      "0.12497981535105517\n",
      "0.12497960685541026\n",
      "0.12497939836112339\n",
      "0.1249791749682903\n",
      "0.12497896647677242\n",
      "0.12497875798664221\n",
      "0.12497853459803372\n",
      "0.12497832611072672\n",
      "0.12497811762483738\n",
      "0.12497789424053853\n",
      "0.1249776857575319\n",
      "0.12497746237616077\n",
      "0.12497723899627004\n",
      "0.12497703051767246\n",
      "0.12497680714077651\n",
      "0.12497658376539765\n",
      "0.12497637529130289\n",
      "0.12497615191898082\n",
      "0.12497592854821025\n",
      "0.12497570517900267\n",
      "0.12497548181136896\n",
      "0.12497525844532385\n",
      "0.12497503508087349\n",
      "0.12497481171803587\n",
      "0.12497458835682074\n",
      "0.1249743649972396\n",
      "0.12497414163930577\n",
      "0.12497391828303256\n",
      "0.12497369492843012\n",
      "0.12497347157551518\n",
      "0.12497323332473333\n",
      "0.12497300997523925\n",
      "0.12497278662747462\n",
      "0.12497254838192629\n",
      "0.12497232503766673\n",
      "0.12497208679567597\n",
      "0.12497186345497935\n",
      "0.12497162521660697\n",
      "0.12497138698007139\n",
      "0.12497116364483145\n",
      "0.12497092541200447\n",
      "0.12497068718105717\n",
      "0.12497044895200721\n",
      "0.12497021072487352\n",
      "0.12496997249966901\n",
      "0.12496973427640216\n",
      "0.12496949605510205\n",
      "0.12496925783577825\n",
      "0.12496901961844831\n",
      "0.12496878140313195\n"
     ]
    }
   ],
   "source": [
    "for iter in range(100):\n",
    "    print(optim.train(input_indices,output_indices,target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_sample = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<linguamind.linalg.Tensor; proxy of <Swig Object of type 'Tensor *' at 0x1078b4e70> >"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn0 = nn.SparseLinearInput(1000,50)\n",
    "syn0.weights.uniform()\n",
    "syn0.weights -= 0.5\n",
    "syn0.weights /= 50\n",
    "\n",
    "syn1 = nn.SparseLinearOutput(50,1000,n_sample)\n",
    "syn1.weights.uniform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp = nn.Sequential()\n",
    "mlp.add(syn0)\n",
    "mlp.add(syn1)\n",
    "\n",
    "criterion = nn.MSECriterion(1,n_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = la.Tensor((1,10))\n",
    "target.zero()\n",
    "target.set(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "context_indices = (1,2,4,5)\n",
    "pred = 3\n",
    "neg_samples = list([6,7,8,9,10,11,12,13,14])\n",
    "target_indices = list([pred]) + neg_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "criterion.forwards(mlp.forward(context_indices,target_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<linguamind.linalg.Tensor; proxy of <Swig Object of type 'Tensor *' at 0x1078b4630> >"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion.backwards(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input = la.Tensor((1,50)).uniform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "syn1.updateOutput(input,(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "syn1.output.get(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = nlp.Text(\"hello world\",\"BIIIIOBIIII\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = text.getVocab(\"tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text.getSequence('tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# text = lm.Text(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = lm.Text(\"hello world\",\"BIIIIOBIIII\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab = text.getVocab(\"tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(vocab.size):\n",
    "    print vocab.getTermAtIndex(i).letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text.getSequence(\"tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#NLP Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two Types of Component:\n",
    "- word level\n",
    "- sentence level\n",
    "- document level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = lm.Text(\"/my/folder/of/files\") # atempts to autodetect file type\n",
    "c = lm.Text(path=\"myfile.txt\",type=\"raw\")\n",
    "c = lm.Text(path=\"myfile.txt\",type=\"csv-token\") # one token per line in CSV\n",
    "c = lm.Text(path=\"myfile.txt\",type=\"csv-segment\") # text segment per line in CSV\n",
    "c = lm.Text(path=\"myfile.txt\",type=\"prefix__label__\") # one sentence per line with special labels\n",
    "c = lm.Text(path=\"myfile.txt\",type=\"json\")\n",
    "\n",
    "# document level raw text\n",
    "d1 = lm.Text(\"This is my sentence.\")\n",
    "d2 = lm.Text(\"myfile.txt\")\n",
    "\n",
    "c = lm.Text([d1,d2]) #form documents into Corpus\n",
    "\n",
    "# document level text with labels\n",
    "contents = {}\n",
    "contents[\"text\"] = \"This is my sentence. This is another one.\"\n",
    "contents[\"date\"] = 1997\n",
    "d = lm.Text(contents)\n",
    "\n",
    "# sentence level text with labels\n",
    "contents = {}\n",
    "contents[\"text\"] = \"This is my sentence.\"\n",
    "contents[\"sentiment\"] = \"Positive\"\n",
    "contents[\"speaker\"] = \"John Locke\"\n",
    "d = lm.Text(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tok = lm.Segmenter(name=\"tokenizer\",lang=\"en\")\n",
    "eos = lm.Segmenter(name=\"eos\",lang=\"en\")\n",
    "\n",
    "# document level text with labels\n",
    "contents = {}\n",
    "contents[\"text\"] = \"This is my sentence. This is another one.\"\n",
    "contents[\"date\"] = 1997\n",
    "d = lm.Text(contents)\n",
    "\n",
    "tok.segment(d)\n",
    "eos.segment(d)\n",
    "\n",
    "print d[\"text\"] # \"This is my sentence. This is another one.\"\n",
    "print d[\"tokens\"] # [\"This\", \"is\"...\n",
    "print d[\"sentences\"] # [[\"This\", \"is\", \"my\", \"sentence\",\".\"],[\"This\",\"is\",\"another\",\"one\",\".\"]]                \n",
    "                     \n",
    "pos = lm.Classifier(name=\"pos\")\n",
    "pos.predict(d)\n",
    "\n",
    "print d[\"sentences\"] # [[{\"token\":\"This\",\"POS\":\"NNP\"},...                \n",
    "\n",
    "sentiment = lm.Classifier(name=\"sentiment\")\n",
    "sentiment.predict(d)\n",
    "print d[\"sentences\"] # [{\"sentiment\":\"Positive\",\"tokens\":[{\"token\":\"This\",\"POS\":\"NNP\"},..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Creating Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a Segmenter (tokenizer)\n",
    "contents = {}\n",
    "contents[\"text\"] = \"I like pie.\"\n",
    "contents[\"char_segs\"] = \"BOBIIIOBIIB\"\n",
    "d = lm.Text(contents)\n",
    "\n",
    "feats=[[\"text_-2\",\"text_-1\"],\"text_-1\",\"text_0\",\"text_1\",[\"text_1\",\"text_2\"]]\n",
    "\n",
    "ambiguity_hash = lm.AmbiguityHash(d,feats,\"char_segs\",threshold=0.95,min_count=5)\n",
    "\n",
    "percept_model = lm.ml.Sequential()\n",
    "percept_model.add(lm.ml.Linear(size=[d.getVocab(\"text\").size() * 10],encoding=\"hashtable\"))\n",
    "percept_model.add(lm.ml.LogSoftmax())\n",
    "\n",
    "percept_loss = lm.ml.PerceptronLoss()\n",
    "percept_optimizer = lm.ml.optim.PerceptronUpdate()\n",
    "percept_searcher = lm.ml.search.BeamSearch(beam=5)\n",
    "\n",
    "# where available in leau of calling all the forward/backprop logic from Python slowing things down\n",
    "tokenizer = lm.ml.trainer.FastSegmentationTrainer(d,\"char_segs\",feats,percept_model,percept_loss,percept_searcher,inherits=[ambiguity_hash],threads=50)\n",
    "\n",
    "tokenizer.segment(d,\"tokens\") #generates new vocab for what was segmented\n",
    "\n",
    "eos = lm.pretrained.Segmenter(name=\"eos\",lang=\"en\")\n",
    "eos.segment(d,\"sentences\",ignore_vocab=True) # does not generate a new vocab for what was segmented\n",
    "\n",
    "# https://github.com/oxford-cs-ml-2015/practical6/blob/master/train.lua\n",
    "lstm_hidden = 50\n",
    "seq_length = 16\n",
    "\n",
    "layers = list()\n",
    "for i in range(seq_length):\n",
    "    layer = {}\n",
    "    \n",
    "    inputs = {}\n",
    "    layer['embed'] = lm.ml.Embedding(d.getVocab(\"token\").size(),lstm_hidden)\n",
    "    layer['lstm'] = lm.ml.LSTM(lstm_hidden,input_x=layer['embed'],input_h=layers[i-1]['lstm']['h'])\n",
    "    layer['softmax'] = lm.ml.LogElasticHierarchicalSoftmax(input=layer['lstm']['h'],size=(lstm_hidden,d.getVocab(\"token\").size()),sample_rate=0.001)\n",
    "    layer['criterion'] = lm.ml.LogElasticHierarchicalSoftmaxLoss()\n",
    "    layers.append(layer)\n",
    "\n",
    "word_language_model_searcher = lm.ml.search.BeamSearch(beam=5)\n",
    "percept_optimizer = lm.ml.optim.SGD()\n",
    "word_language_model = lm.ml.trainer.FastLanguageModelTrainer(d,layers,word_language_model_searcher,percept_optimizer,predict_on=\"token\",bound_on=\"sentence\",threads=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ML Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ambiguity Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Perceptron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Neural Index"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
